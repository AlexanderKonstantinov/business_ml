{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Урок 5. #Задача оттока: варианты постановки, возможные способы решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 1: объясните своими словами смысл метрик Precison, Recall *\n",
    "1. Какова их взаимосвязь и как с ними связан порог вероятности? \n",
    "2. Можно ли подобрать порог так, что recall будет равен 1? Что при этом будет с precision\n",
    "3. Аналогичный вопрос про precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision отражает точность определения целевого класса, т. е. долю правильно предсказанных объектов.\n",
    "Recall характеризует полноту охвата объектов целевого класса, т. е. долю объектов целевого класса от общего количества объектов.\n",
    "\n",
    "Они, как правило, имеют обратную зависимость, т. к. с ростом порога будет расти точность, а с уменьшением - полнота. \n",
    "\n",
    "Чтобы recall был равен 1, FN должен быть равен 0, а порого должен минимизироваться. Такое возможно в случает отсутствия ошибки 2-го рода - все объекты целевого класса должны быть правильно предсказаны. \n",
    "Возможны следующие варианты: \n",
    "- идеальная модель;\n",
    "- дисбаланс классов (Отсутствие объектов целевого класса в тестовой выборке); \n",
    "- модель, присваивающая всем объектам метку целевого класса.\n",
    "\n",
    "Чтобы precision был равен 1, FP должен быть равен 0, а порог должен максимизироваться. Такое возможно в случает отсутствия ошибки 1-го рода - все предсказанные объекты целевого класса действительно должны относиться к целевому классу. \n",
    "Возможны следующие варианты: \n",
    "- идеальная модель;\n",
    "- дисбаланс классов (все объекты в тестовой выборке относятся к целевому классу).\n",
    "\n",
    "Стоит отметить, что в случае с recall мы можем искуственно создать условия, при которых данная метрика будет равна 1 (порог = 0). В случае precision, задав порог = 1, мы должны иметь модель хорошо разделяющая классы объектов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вопрос 2: предположим, что на удержание одного пользователя у нас уйдет 1 доллар. При этом средняя ожидаемая прибыль с каждого TP (true positive) - 2 доллара. Оцените качество модели выше с учетом этих данных и ответьте на вопрос, является ли она потенциально экономически целесообразной?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1673"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP, FP = 1832, 159\n",
    "\n",
    "profit = TP * 2 - (TP + FP) * 1\n",
    "profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Exited'], random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in self.columns:\n",
    "            if col_ not in test_columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Geography', 'Gender', 'Tenure', 'HasCrCard', 'IsActiveMember']\n",
    "continuous_columns = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "\n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "        ('selector', FeatureSelector(column=cat_col)),\n",
    "        ('ohe', OHEEncoder(key=cat_col))\n",
    "    ])\n",
    "    final_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for cont_col in continuous_columns:\n",
    "    cont_transformer = Pipeline([\n",
    "        ('selector', NumberSelector(key=cont_col)),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "    final_transformers.append((cont_col, cont_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'RandomForestClassifier': Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', RandomForestClassifier(random_state = 42))]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', LogisticRegression(random_state = 42))]),\n",
    "    'CatBoostClassifier': Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', CatBoostClassifier(random_state = 42, silent=True))])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем структуру таблицы со статистикой\n",
    "\n",
    "valid_cols = ['mean roc auc', 'roc auc std']\n",
    "\n",
    "test_cols = ['threshold',\n",
    "        'precision',\n",
    "        'recall',\n",
    "        'fscore',\n",
    "        'roc auc',\n",
    "        'profit']\n",
    "\n",
    "cols_names = [('validation', c) for c in valid_cols] + [('test', c) for c in test_cols]\n",
    "\n",
    "multi_cols = pd.MultiIndex.from_tuples(cols_names)\n",
    "stat_df = pd.DataFrame(columns=multi_cols, index=classifiers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">validation</th>\n",
       "      <th colspan=\"6\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean roc auc</th>\n",
       "      <th>roc auc std</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>roc auc</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.84698</td>\n",
       "      <td>0.0208367</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.654397</td>\n",
       "      <td>0.628684</td>\n",
       "      <td>0.641283</td>\n",
       "      <td>0.863699</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.761725</td>\n",
       "      <td>0.0210729</td>\n",
       "      <td>0.289522</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.56778</td>\n",
       "      <td>0.5097</td>\n",
       "      <td>0.772077</td>\n",
       "      <td>1319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.861037</td>\n",
       "      <td>0.0178314</td>\n",
       "      <td>0.386362</td>\n",
       "      <td>0.661191</td>\n",
       "      <td>0.632613</td>\n",
       "      <td>0.646586</td>\n",
       "      <td>0.876942</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         validation                  test                      \\\n",
       "                       mean roc auc roc auc std threshold precision    recall   \n",
       "RandomForestClassifier      0.84698   0.0208367      0.38  0.654397  0.628684   \n",
       "LogisticRegression         0.761725   0.0210729  0.289522    0.4624   0.56778   \n",
       "CatBoostClassifier         0.861037   0.0178314  0.386362  0.661191  0.632613   \n",
       "\n",
       "                                                   \n",
       "                          fscore   roc auc profit  \n",
       "RandomForestClassifier  0.641283  0.863699   1675  \n",
       "LogisticRegression        0.5097  0.772077   1319  \n",
       "CatBoostClassifier      0.646586  0.876942   1661  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (name, classifier) in classifiers.items():\n",
    "    # запустим кросс-валидацию\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "\n",
    "    # обучим пайплайн на всем тренировочном датасете и предскажем значения тестовой выборки\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_score = classifier.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    b = 1\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "    fscore = (1 + b ** 2) * (precision * recall) / (b ** 2 * precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)    \n",
    "    roc_auc = roc_auc_score(y_test.values, y_score)\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_score > thresholds[ix])\n",
    "    TP, FP = cnf_matrix[0][:]\n",
    "    profit = TP * 2 - (TP + FP) * 1\n",
    "    \n",
    "    stat_df.at[name, ('validation', 'mean roc auc')] = cv_score\n",
    "    stat_df.at[name, ('validation', 'roc auc std')] = cv_score_std\n",
    "    stat_df.at[name, ('test', 'threshold')] = thresholds[ix]\n",
    "    stat_df.at[name, ('test', 'precision')] = precision[ix]\n",
    "    stat_df.at[name, ('test', 'recall')] = recall[ix]\n",
    "    stat_df.at[name, ('test', 'fscore')] = fscore[ix]\n",
    "    stat_df.at[name, ('test', 'roc auc')] = roc_auc  \n",
    "    stat_df.at[name, ('test', 'profit')] = profit   \n",
    "    \n",
    "stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод: наиболее подходящей метрикой в данном случае будет являться f-score, так как нам нужно добиться максимизации прибыли, что складывается из максимального значения TP и минимального значения FP (см. вопрос 2). Лучше себя показала модель градиентного бустинга на основе CatBoost.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров модели CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем таблицу со статистикой\n",
    "\n",
    "stat_df_cat_boost = pd.DataFrame(\n",
    "    data=None, \n",
    "    columns=stat_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators [10, 20, 50, 100, 500]\n",
      "max_depth [2, 3, 5, 10, 15]\n",
      "class_weights [[1, 1], [1, 2], [1, 3], [1, 3.5]]\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем наборы параметров и pipelines с классификаторами\n",
    "# (по-хорошему нужно сделать одинаковую предообработку)\n",
    "\n",
    "trees = [10, 20, 50, 100, 500]\n",
    "depths = [2, 3, 5, 10, 15]\n",
    "weights = [[1, 1], [1, 2], [1, 3], [1, 3.5]]\n",
    "\n",
    "params = {'n_estimators':[10, 20, 50, 100, 500],\n",
    "          'max_depth':[2, 3, 5, 10, 15],\n",
    "          'class_weights': [[1, 1], [1, 2], [1, 3], [1, 3.5]]}\n",
    "\n",
    "classifiers = {}\n",
    "\n",
    "for n_tree in trees:\n",
    "    for depth in depths:\n",
    "        for weight in weights:\n",
    "\n",
    "classifiers = {\n",
    "    'RandomForestClassifier': Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', RandomForestClassifier(random_state = 42))]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', LogisticRegression(random_state = 42))]),\n",
    "    'CatBoostClassifier': Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', CatBoostClassifier(random_state = 42, silent=True))])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df_cat_boost = pd.DataFrame(\n",
    "    data=None, \n",
    "    columns=stat_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">validation</th>\n",
       "      <th colspan=\"6\" halign=\"left\">test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean roc auc</th>\n",
       "      <th>roc auc std</th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>roc auc</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(validation, mean roc auc), (validation, roc auc std), (test, threshold), (test, precision), (test, recall), (test, fscore), (test, roc auc), (test, profit)]\n",
       "Index: []"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df_cat_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
